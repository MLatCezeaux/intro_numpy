{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Nearest neighbors computation\n",
    "\n",
    "This notebook contains practical exercise to manipulate the $k$ nearest neighbors of a particular observation under study, the so called **kNN aglorithm**, standing for *k Nearest Neighbor*.\n",
    "\n",
    "## Import and pseudo-datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot settings\n",
    "mpl.rcParams['legend.frameon'] = False\n",
    "mpl.rcParams['legend.fontsize'] = 'xx-large'\n",
    "mpl.rcParams['xtick.labelsize'] = 16\n",
    "mpl.rcParams['ytick.labelsize'] = 16\n",
    "mpl.rcParams['axes.titlesize'] = 18\n",
    "mpl.rcParams['axes.labelsize'] = 18\n",
    "mpl.rcParams['lines.linewidth'] = 2.5\n",
    "mpl.rcParams['figure.figsize'] = (10, 7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following piece of code create two reference dataset (*training*) containing 1 million observation, each observation consist of 25 variables (or *features*). For the purpose of the exercise, we use gaussian numbers with a mean of -3.5 and +3.5 for training dataset 1 and 2 respectively (both having a RMS of 5)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generation of two (training) datasets of 10e6 observations contanining 25 features each\n",
    "Nobs = 1000000\n",
    "trainX1 = 5.0*np.random.randn(Nobs,25) - 3.5\n",
    "trainX2 = 5.0*np.random.randn(Nobs,25) + 3.5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since our training dataset is known, it can be useful to consider labels associated to each event. This label is the property we might want to predict for a new, unknown observation. We decide to label `trainX1` with `1` and `trainX2` with `2`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the target (or label for each dataset)\n",
    "trainY1 = np.zeros(Nobs)+1\n",
    "trainY2 = np.zeros(Nobs)+2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quick data inspection\n",
    "\n",
    "Plot and compare the distribution of the first variables for `trainX1` and `trainX2`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Nearest neighbors of a new observation `obs`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1.5163353   0.46745905 -1.9749674   0.81847287 -2.10605451 -0.72111832\n",
      " -0.88742104 -0.36341393  0.66966908 -0.82492674 -0.64401129 -0.50158702\n",
      "  0.34686495  1.23418421  1.59275961 -0.4346808  -1.12086931 -1.40398098\n",
      " -0.95557966  0.36802226 -0.35896868 -1.65525595  1.31616685  0.48097986\n",
      " -0.36436321]\n"
     ]
    }
   ],
   "source": [
    "obs = np.random.randn(25)\n",
    "print(obs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merge the two datasets `X` and `Y`\n",
    "\n",
    "The idea is to manipulate a single array `trainX` for the features regardless of the type of data (1 or 2), while keeping track of the label with a single `trainY` array:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainX = np.concatenate([trainX1, trainX2])\n",
    "trainY = np.concatenate([trainY1, trainY2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute the distance between `obs` and the global dataset\n",
    "\n",
    "Using broadcasting and vectorized operation, compute the euclidien distance in the 25 dimension space between the unknown observation and every point of the global dataset (containing both data of type 1 and 2)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sort the distances to have the nearest points first\n",
    "\n",
    "In this question, we want to sort distances by increasing order (to later take only the $k$ first ones), and the associated type of neighbors (1 or 2). \n",
    "\n",
    "**HINT:** this can be done using the function `np.argsort()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vizualize the observation and its neighbors in a 2D projection\n",
    "\n",
    "We would like to vizualize the observation and its 100 nearest neighbors in the 2D projection of the two first features. Produce a scatter plot showing the observation and the 100 nearest neighbors with different color for different types, and markersize depending on the 2D distance.\n",
    "\n",
    "**HINT:** one can use fancy indexing, considering that `sorted_points[:100]` is the indices of the 100 nearest neighbors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Count the number of nearest neighbors of type 1 and type 2 \n",
    "\n",
    "We would like to consider the k nearest neighbors, and count the fraction of type 1 and type 2 data (to later be able to say if our unknown observation is more likely to be of type 1 or 2). Of course, if we consider the whole training points (`k=Nobs`), there will be `Nobs` points of type 1 and `Nobs` points of type 2. This is why it is interesting to compute the number of type 1 and type 2 neihbors *as a function of k*. We will consider all k values from 1 to 500.\n",
    "\n",
    "**HINT:** the function `np.cumsum()` might be useful."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot the number of neighbors of type 1 and type 2 as a function of $k$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a function `get_kNN_obs()` doing all this at once\n",
    "\n",
    "We want now to have a function taking in argument an observation, a training sample trainX and a target trainY *with an arbitray number of type of data*, which returns the number of nearest neighbors up to kmax for each data type (formated into a list). In other words, we want a function returning `[N1, N2, ... Nj]`, where `Ni` is numpy 1D array of shape `(kmax,)` containing the number of neighbor of type `i` among the `k` nearest neighbors -- up to `kmax`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Nearest neighbors of a new set of unknown observations `testX`\n",
    "\n",
    "### Preparing the proper broadcasting\n",
    "\n",
    "In this part, we want to repeat the operation previously made for one observation, on an entire dataset. This is possible using broadcasting. What is the proper re-shaping in order to get an array of shape `(Nobs, Ntrain, Nvar)` from two arrays of shape `(Nobs, Nvar)` and `(Ntrain, Nvar)`? \n",
    "\n",
    "**HINT:** we can use the `a.reshape()` to add an *empty axis* at the right position."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "d1 = np.random.randn(10, 3)\n",
    "t1 = np.random.randn(5, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# t1+d1 will crash with \"could not be broadcast together with shapes (5,3) (10,3)\"\n",
    "# Find what has to be done"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generalize  `get_kNN_obs()` to run over a dataset\n",
    "\n",
    "Here, we want a function returning `[N1, N2, ... Nj]`, where `Ni` is numpy *2D array* of shape `(Nobs, kmax)` containing the number of neighbor of type `i` among the `k` nearest neighbors - up to `kmax` - for each observation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generation of unknown pseudo-data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate pseudo data like data1 and data2\n",
    "data_obs_like1 = 3*np.random.randn(10000, 25) - 2.5\n",
    "data_obs_like2 = 3*np.random.randn(10000, 25) + 2.5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Memory limit - lazy *v.s* eager learner\n",
    "\n",
    "This algorithm needs to loop over all training observation for each unknown observation. This is called a *lazy learner*, as opposed to the *eager learner* which can be evaluated for each unknown observation without the training sample. This might causes trouble in case of large dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'get_kNN_data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-e100d513506c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# This will crash with a memory error\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mget_kNN_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_obs_like1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrainX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrainY\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'get_kNN_data' is not defined"
     ]
    }
   ],
   "source": [
    "# This will crash with a memory error\n",
    "get_kNN_data(data_obs_like1, trainX, trainY)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write a function `kNNprediction(dataX, trainX, trainY, k, ntrain)` which takes only `ntrain` events of the training sample (equally sampled in the array, *i.e.* **not** the first `ntrain` elements of the training sample) and run the kNN computation.\n",
    "\n",
    "**HINT:** it's recommanded to remain below a size of 1000000. Since our unknown dataset are have 10000 observations, it's better to not considere more than few 1000 training events."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Call this function on both `data_obs_like1` and `data_obs_like2` and plot the fraction of k nearest neibghors of type 1 for each unknown dataset. Compare how the discriminative power changes with $k$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Computing the nearest neighbors with many categories\n",
    "\n",
    "### Generation of a training dataset with 5 types of data\n",
    "\n",
    "We first create a more complex dataset contanining 5 different populations stored in `trainX_ndata`, with five different averages. The associated labels are in `trainY_ndata`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Nobs = 10000\n",
    "mulist = [-5, -2, 0, 2, 5]\n",
    "dlist = [5.0*np.random.randn(Nobs,25)+mu for mu in mulist]\n",
    "llist = [np.zeros(Nobs)+i for i in np.arange(len(mulist))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainX_ndata = np.concatenate(dlist)\n",
    "trainY_ndata = np.concatenate(llist)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Number of neighbor of each population\n",
    "\n",
    "The goal here is to have a function which return the number of neighbors for each population among the $k$ nearest neighbors. In otherwords, we want the composition of the $k$ nearest neighbors.\n",
    "\n",
    "**HINT:** Since the number and the nature of label is *a priori* unknown, it might be convenient to store the information into a dictionnary `{label: n_kNN_label}`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Behaviour on two different unknown pseud-data\n",
    "\n",
    "We first generate two sample of pseudo-unknown pseudo-dataset which look like population 1 and population 3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate pseudo data like data1 and data2\n",
    "data_obs_pop1 = 3*np.random.randn(10000, 25) - 2\n",
    "data_obs_pop3 = 3*np.random.randn(10000, 25) + 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write a function `plot_kNN_composition(k)` which plots the number of neighbors of each population among the $k$ nearest neighbors, for the two above pseudo-datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
